{"componentChunkName":"component---src-pages-supporting-infrastructure-mq-mq-on-openshift-mdx","path":"/supporting-infrastructure/mq/mq-on-openshift/","result":{"pageContext":{"frontmatter":{"title":"MQ on OpenShift","description":"MQ on OpenShift","tabs":["MQ Overview","MQ on IKS","MQ on OpenShift","MQ Containers"]},"relativePagePath":"/supporting-infrastructure/mq/mq-on-openshift.mdx","titleType":"page","MdxNode":{"id":"401d9077-f988-5c8d-b08b-e96d838c18c5","children":[],"parent":"5c85bf10-6d4f-51ea-84cb-6a47f176386c","internal":{"content":"---\ntitle: MQ on OpenShift\ndescription: MQ on OpenShift\ntabs: ['MQ Overview','MQ on IKS', 'MQ on OpenShift','MQ Containers']\n---\n\n## Support for IBM MQ certified containers on OpenShift\n\nIBM® Cúram Social Program Management (SPM) customers may obtain IBM MQ certified containers from the IBM Cloud Container Registry for use as a Supporting Program for SPM.\nUse as a Supporting Program means that IBM MQ certified containers can only be used to process internal JMS messages within SPM.\n\nSPM does not require or support the use of any IBM MQ Advanced features available in the IBM MQ certified containers.\n\nIBM MQ certified container is supported only on SPM Version 7.0.11 and later versions.\n\n<InlineNotification>\n\n**Note**: The IBM MQ charts found in the Runbook Github repository are sample charts based on the IBM MQ public charts published [here](https://github.com/IBM/charts/tree/master/stable/ibm-mqadvanced-server-dev).\n\n</InlineNotification>\n\n## Stateful Sets\n\nIf a highly available MQ cluster is desired, a **Stateful Set** can be used. The stateful set used for SPM contains two identical\npods, one active pod and one standby pod. If the active pod goes down, the standby pod is moved into the active role and a new pod is rescheduled in standby mode.\nThis occurs seamlessly, with persistent storage allowing for minimal downtime. The Stateful Set used in SPM requires several values that must be configured prior to\ndeployment. These values are those located under the MQ `multiInstance` section within the relevant values file. There, NFS or Ceph can be chosen as the desired\nmulti-instance delivery method.\n\n* **NFS** - In order to deploy with NFS, an NFS server and NFS folder must be available and configured; i.e. the destination directory `global.mq.multiInstance.nfsFolder` must exist;\nthe folder must be configured to have a `data` and `logs` subdirectory for each applicable application (i.e. if `global.mq.multiInstance.nfsFolder` is set to `/MQHA`, the folder must\ncontain the directories `/MQHA/curam/data`, `/MQHA/curam/logs` etc).\nThe supplementalGroups may need to be provided depending on the NFS server security setup.\n* **Ceph** - In order to deploy with Ceph, the desired Storage Class must be provided.\n\n## PersistentVolumes and PersistentVolumeClaims\n\nA `PersistentVolume` (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.\nIt is a resource in the cluster just like a node is a cluster resource. A `PersistentVolumeClaim` (PVC) is a request for storage by a user. It is similar to\na Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific\nsize and access modes.\n\nWhen using NFS as the desired multi-instance method, the PV and PVCs must be configured by the user. Within the PVs, the NFS IP and NFS folder must be provided.\nIn the PV, a `claimRef` can be defined in order to ensure that the correct PVC matches with the correct PV. The templates provided also contain labels, which can\nalso be used to ensure correct coupling.\n\nIf using Ceph, the PVs are dynamically configured. Therefore, no further configuration is required.\n\n## Operators\n\nMQ can also be deployed via Operators. Operators are a method of packaging and deploying Kubernetes applications that take human operational knowledge of managing the application and encode it into the\npackage itself, which can then be shared with users. Operator deployment can be used to create a single-instance or a multi-instance deployment, as desired.  \n\nThe IBM MQ Operator can be installed using the Operator Hub. More information on  installing the IBM Operator using the OpenShift CLI\ncan be found [here](https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_9.1.0/com.ibm.mq.ctr.doc/ctr_installing_cli.htm).  \nWhen deploying in this way, a **Queue Manager** object is created. The Operator deployment also handles the creation of the **PersistentVolume** and **Stateful Set** objects.\n","type":"Mdx","contentDigest":"07940c427f64dcce117f4c534b6fa79a","owner":"gatsby-plugin-mdx","counter":208},"frontmatter":{"title":"MQ on OpenShift","description":"MQ on OpenShift","tabs":["MQ Overview","MQ on IKS","MQ on OpenShift","MQ Containers"]},"exports":{},"rawBody":"---\ntitle: MQ on OpenShift\ndescription: MQ on OpenShift\ntabs: ['MQ Overview','MQ on IKS', 'MQ on OpenShift','MQ Containers']\n---\n\n## Support for IBM MQ certified containers on OpenShift\n\nIBM® Cúram Social Program Management (SPM) customers may obtain IBM MQ certified containers from the IBM Cloud Container Registry for use as a Supporting Program for SPM.\nUse as a Supporting Program means that IBM MQ certified containers can only be used to process internal JMS messages within SPM.\n\nSPM does not require or support the use of any IBM MQ Advanced features available in the IBM MQ certified containers.\n\nIBM MQ certified container is supported only on SPM Version 7.0.11 and later versions.\n\n<InlineNotification>\n\n**Note**: The IBM MQ charts found in the Runbook Github repository are sample charts based on the IBM MQ public charts published [here](https://github.com/IBM/charts/tree/master/stable/ibm-mqadvanced-server-dev).\n\n</InlineNotification>\n\n## Stateful Sets\n\nIf a highly available MQ cluster is desired, a **Stateful Set** can be used. The stateful set used for SPM contains two identical\npods, one active pod and one standby pod. If the active pod goes down, the standby pod is moved into the active role and a new pod is rescheduled in standby mode.\nThis occurs seamlessly, with persistent storage allowing for minimal downtime. The Stateful Set used in SPM requires several values that must be configured prior to\ndeployment. These values are those located under the MQ `multiInstance` section within the relevant values file. There, NFS or Ceph can be chosen as the desired\nmulti-instance delivery method.\n\n* **NFS** - In order to deploy with NFS, an NFS server and NFS folder must be available and configured; i.e. the destination directory `global.mq.multiInstance.nfsFolder` must exist;\nthe folder must be configured to have a `data` and `logs` subdirectory for each applicable application (i.e. if `global.mq.multiInstance.nfsFolder` is set to `/MQHA`, the folder must\ncontain the directories `/MQHA/curam/data`, `/MQHA/curam/logs` etc).\nThe supplementalGroups may need to be provided depending on the NFS server security setup.\n* **Ceph** - In order to deploy with Ceph, the desired Storage Class must be provided.\n\n## PersistentVolumes and PersistentVolumeClaims\n\nA `PersistentVolume` (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.\nIt is a resource in the cluster just like a node is a cluster resource. A `PersistentVolumeClaim` (PVC) is a request for storage by a user. It is similar to\na Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific\nsize and access modes.\n\nWhen using NFS as the desired multi-instance method, the PV and PVCs must be configured by the user. Within the PVs, the NFS IP and NFS folder must be provided.\nIn the PV, a `claimRef` can be defined in order to ensure that the correct PVC matches with the correct PV. The templates provided also contain labels, which can\nalso be used to ensure correct coupling.\n\nIf using Ceph, the PVs are dynamically configured. Therefore, no further configuration is required.\n\n## Operators\n\nMQ can also be deployed via Operators. Operators are a method of packaging and deploying Kubernetes applications that take human operational knowledge of managing the application and encode it into the\npackage itself, which can then be shared with users. Operator deployment can be used to create a single-instance or a multi-instance deployment, as desired.  \n\nThe IBM MQ Operator can be installed using the Operator Hub. More information on  installing the IBM Operator using the OpenShift CLI\ncan be found [here](https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_9.1.0/com.ibm.mq.ctr.doc/ctr_installing_cli.htm).  \nWhen deploying in this way, a **Queue Manager** object is created. The Operator deployment also handles the creation of the **PersistentVolume** and **Stateful Set** objects.\n","fileAbsolutePath":"/home/travis/build/IBM/spm-kubernetes/src/pages/supporting-infrastructure/mq/mq-on-openshift.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}